{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as scheduler\nimport transformers\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import f1_score\nimport numpy as np\nfrom tqdm.autonotebook import tqdm\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    device='cuda'if torch.cuda.is_available() else 'cpu'\n    train_batch_size=8\n    val_batch_size=8\n    seed=5\n    n_splits=5\n    pooler_output_dim=768\n    metric=f1_score\n    lr=1e-4\n    step_size=10\n    gamma=0.1\n    epochs=5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint=\"bert-base-cased\"\nbert=transformers.AutoModel.from_pretrained(checkpoint)\nbert_tokenizer=transformers.AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndata['sentiment']=list(map(lambda x : 1 if x==\"positive\" else 0,data['sentiment'].values))\n\n\nfrom sklearn.model_selection import StratifiedKFold\ndata.loc[:,'kfold']=-1\ndata.sample(frac=1,random_state=Config.seed).reset_index(drop=True)\nlabels=data['sentiment'].values\nskf=StratifiedKFold(n_splits=Config.n_splits)\n\nfor fold,(train,val) in enumerate(skf.split(X=data,y=data['sentiment'])):\n    data.loc[val,'kfold']=fold\ndata.to_csv('/kaggle/working/folds.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ReviewData:\n    def __init__(self,data):\n        self.data=data.reset_index(drop=True)\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        review=bert_tokenizer(self.data['review'][idx],truncation=True,max_length=300,padding='max_length',return_tensors='pt')\n        sentiment=torch.tensor(self.data['sentiment'][idx],dtype=torch.long)\n        return {'x':{k:v.to(device=Config.device) for k,v in review.items()},'y':sentiment.to(device=Config.device)}\n\n    \n    \nclass Classif_Model(nn.Module):\n    def __init__(self,bert_model,hidden_shape,out_shape):\n        super().__init__()\n        self.bert_model=bert_model\n        self.hidden_shape=hidden_shape\n        self.out_shape=out_shape\n        self.layers=nn.Sequential(\n            nn.Linear(Config.pooler_output_dim,hidden_shape),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.1),\n            nn.Linear(hidden_shape,out_shape)\n        \n        )\n    \n    def forward(self,batch):\n        out=self.bert_model(batch)\n        out=out['pooler_output']\n        out=self.layers(out)\n        return out\n    \nmodel=Classif_Model(bert,100,2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Train:\n    def __init__(self,model,criterion,optimizer,scheduler):\n        self.model=model\n        self.criterion=criterion\n        self.optimizer=optimizer\n        self.scheduler=scheduler\n    \n    @staticmethod\n    def logits_to_prediction(output):\n        preds=torch.argmax(torch.softmax(output.detach().to('cpu'),dim=-1),dim=-1)\n        return preds.view(1,-1)\n    @staticmethod\n    def return_metric(preds,labels):\n        return Config.metric(preds.to('cpu'),labels.to('cpu'),average='weighted')\n    \n    def fit(self,data_loader):\n        self.model.train()\n        for batch in data_loader:\n            out=self.model(batch['x']['input_ids'].squeeze_(1)) \n            loss=self.criterion(out,batch['y'])\n            loss.backward()\n            self.optimizer.zero_grad()\n            self.optimizer.step()\n            self.scheduler.step()\n            \n    def predict_metric(self,data_loader,type_='train'):\n        batch_loss=0\n        if type_=='train':\n            batch_size=Config.train_batch_size\n        elif type_=='val':\n            batch_size=Config.val_batch_size\n            \n        preds=torch.empty([len(data_loader),batch_size])\n        labels=torch.empty([len(data_loader),batch_size])\n        \n        with torch.no_grad():\n            self.model.eval()\n            for idx,batch in enumerate(data_loader):\n                out=self.model(batch['x']['input_ids'].squeeze_(1)) \n                batch_loss+=self.criterion(out,batch['y']).item()\n                preds[idx,:]=self.logits_to_prediction(out)\n                labels[idx,:]=batch['y'].to('cpu')\n        \n            metric=self.return_metric(preds,labels)\n        return metric,batch_loss/len(data_loader)\n    \n             \n            \nfolds=pd.read_csv(\"/kaggle/working/folds.csv\")\nmodel=model.to(device=Config.device)\ncriterion=nn.CrossEntropyLoss()\noptimizer=optim.Adam(model.parameters(),lr=Config.lr)\nscheduler=optim.lr_scheduler.StepLR(optimizer,step_size=Config.step_size,gamma=Config.gamma)\ntrain=Train(model,criterion,optimizer,scheduler)\n\nepoch_train_loss=[] #per epoch\nepoch_val_loss=[]   #per epoch\nepoch_train_f1=[]   #per epoch\nepoch_val_f1=[]     #per epoch\n\nfor epoch in tqdm(range(Config.epochs)):\n\n    train_loss=[] \n    val_loss=[]   \n    train_f1=[]   \n    val_f1=[]  \n    \n    for fold in range(Config.n_splits):\n        \n        train_data=DataLoader(ReviewData(folds.loc[folds['kfold']!=fold]),batch_size=Config.train_batch_size,drop_last=True)\n        val_data=DataLoader(ReviewData(folds.loc[folds['kfold']==fold]),batch_size=Config.val_batch_size,drop_last=True)\n        train.fit(train_data)\n        \n        t_f1,t_loss=train.predict_metric(train_data,'train')\n        train_loss.append(t_loss)\n        train_f1.append(t_f1)\n        \n        \n        v_f1,v_loss=train.predict_metric(val_data,'val')\n        val_loss.append(v_loss)\n        val_f1.append(v_f1)\n        \n    epoch_train_loss.append(np.mean(train_loss))\n    epoch_train_f1.append(np.mean(train_f1))\n    epoch_val_loss.append(np.mean(val_loss))\n    epoch_val_f1.append(np.mean(val_f1))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(Config.epochs),epoch_train_loss)\nplt.plot(range(Config.epochs),epoch_val_loss)\nplt.plot(range(Config.epochs),epoch_train_f1)\nplt.plot(range(Config.epochs),epoch_val_f1)\nplt.legend(['train_loss','val_loss','train_f1','val_f1'],bbox_to_anchor=(1.05,1),loc='upper left');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}