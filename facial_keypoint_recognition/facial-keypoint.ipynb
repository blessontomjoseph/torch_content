{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport os\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom tqdm.autonotebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:34:42.724451Z","iopub.execute_input":"2023-03-08T19:34:42.725249Z","iopub.status.idle":"2023-03-08T19:34:46.014829Z","shell.execute_reply.started":"2023-03-08T19:34:42.725190Z","shell.execute_reply":"2023-03-08T19:34:46.013421Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotations=pd.read_csv(\"/kaggle/input/dataset-1-and-dataframe/dataframe/key_points.csv\")\nannotations.volumns=[i.lower() for i in annotations.columns]\nannotations.dropna(axis=0,inplace=True)\nselected_images=set(annotations['img_name'].values)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:34:46.017349Z","iopub.execute_input":"2023-03-08T19:34:46.018130Z","iopub.status.idle":"2023-03-08T19:34:46.102295Z","shell.execute_reply.started":"2023-03-08T19:34:46.018066Z","shell.execute_reply":"2023-03-08T19:34:46.100768Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  \n","output_type":"stream"}]},{"cell_type":"code","source":"data_path_1=\"/kaggle/input/dataset-1-and-dataframe/dataset_1\"\ndata_path_2=\"/kaggle/input/dataset-2/dataset_2\"\n\npath_1_images=list(set(os.listdir(data_path_1)).intersection(selected_images))\npath_2_images=list(set(os.listdir(data_path_2)).intersection(selected_images))\n\nclass Config:\n    num_train_samples=1200\n    num_val_samples=len(path_1_images)+len(path_2_images)-num_train_samples #debugged\n    train_batch_size=2\n    val_batch_size=2\n    epochs=5\n    device= 'cuda'if torch.cuda.is_available else 'cpu'\n    lr=1e-9\n\n\n#debugged -changed os.listdir(data_path_1) and os.listdir(data_path_2) to path_1_images and path_2_images\ntrain_data_list=list(map(lambda x : os.path.join(data_path_1,x),path_1_images))+list(map(lambda x :os.path.join(data_path_2,x),path_2_images[:len(path_2_images)-Config.num_val_samples]))\nval_data_list=list(map(lambda x : os.path.join(data_path_2,x),path_2_images[(len(path_2_images)-Config.num_val_samples):]))\n\n\nclass FaceData:\n    def __init__(self,data,annotations,transforms=None):\n        self.transforms=transforms\n        self.data=data\n        self.annotations=annotations\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self,idx):\n        data=self.data[idx]\n        labels=torch.tensor(self.annotations.loc[annotations['img_name']==data[-9:]].iloc[:,1:].values.reshape(-1,2),dtype=torch.float32)\n        \n        if self.transforms is not None:\n            image=Image.open(data)\n            image=self.transforms(image)\n        \n        return {\"x\":image,'y':labels}\n            \nimage_transforms=transforms.Compose([\n    transforms.ToTensor(),\n    transforms.RandomHorizontalFlip(p=0.5), #can be a hyper param\n    transforms.ColorJitter(brightness=0.2,contrast=0.2,saturation=0.2)\n])\n   \ntrain_data=FaceData(train_data_list,annotations,image_transforms)\nval_data=FaceData(val_data_list,annotations,image_transforms)\n\ntrain_loader=DataLoader(train_data,Config.train_batch_size)\nval_loader=DataLoader(val_data,Config.val_batch_size)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:34:46.104399Z","iopub.execute_input":"2023-03-08T19:34:46.104763Z","iopub.status.idle":"2023-03-08T19:34:46.452802Z","shell.execute_reply.started":"2023-03-08T19:34:46.104731Z","shell.execute_reply":"2023-03-08T19:34:46.451383Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"Config.device","metadata":{"execution":{"iopub.status.busy":"2023-03-08T19:34:46.455994Z","iopub.execute_input":"2023-03-08T19:34:46.456473Z","iopub.status.idle":"2023-03-08T19:34:46.469433Z","shell.execute_reply.started":"2023-03-08T19:34:46.456431Z","shell.execute_reply":"2023-03-08T19:34:46.468167Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"# model\n\nclass KeypointModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1=nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1,bias=True)\n  \n        self.relu1=nn.ReLU(inplace=True)\n        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        self.conv2=nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1,bias=True)\n  \n        self.relu2=nn.ReLU(inplace=True)\n        self.pool2=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        self.conv3=nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1,bias=True)\n  \n        self.relu3=nn.ReLU(inplace=True)\n        self.pool3=nn.MaxPool2d(kernel_size=2,stride=2)\n        \n        self.fc1=nn.Linear(128*64*64,512,bias=True)\n        self.relu4=nn.ReLU(inplace=True)\n        self.fc2=nn.Linear(512,67*2,bias=True)\n        \n    def forward(self,x):\n        x=self.conv1(x)\n        x=self.relu1(x)\n        x=self.pool1(x)\n        \n        x=self.conv2(x)\n        x=self.relu2(x)\n        x=self.pool2(x)\n        \n        x=self.conv3(x)\n        x=self.relu3(x)\n        x=self.pool3(x)\n        \n        x=x.view((-1,128*64*64))\n        x=self.fc1(x)\n        x=self.relu4(x)\n        x=self.fc2(x)\n        x=x.view(-1,67,2)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-03-08T12:46:12.870786Z","iopub.execute_input":"2023-03-08T12:46:12.871151Z","iopub.status.idle":"2023-03-08T12:46:12.885689Z","shell.execute_reply.started":"2023-03-08T12:46:12.871115Z","shell.execute_reply":"2023-03-08T12:46:12.884725Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model=KeypointModel()\nmodel=model.to(device=Config.device)\ncriterion=nn.L1Loss()\noptimizer=torch.optim.AdamW(model.parameters(),lr=Config.lr)\n\n# training\navg_train_loss=[]\navg_val_loss=[]\n\nfor epoch in tqdm(range(Config.epochs)):\n    train_loss=0\n    for batch in train_loader:\n        X=batch['x'].to(device=Config.device)\n        Y=batch['y'].to(device=Config.device)\n        \n        out=model(X)\n        loss=criterion(out,Y)\n        loss.backward()\n        optimizer.zero_grad()\n        optimizer.step()\n        train_loss+=loss.item()\n    train_loss/=len(train_loader)\n    \n    with torch.no_grad():\n        val_loss=0\n        for batch in val_loader:\n            x=batch['x'].to(device=Config.device)\n            y=batch['y'].to(device=Config.device)\n            out=model(x)\n            loss=criterion(out,y)\n            val_loss+=loss.item()\n        val_loss/=len(val_loader)\n    \n    avg_train_loss.append(train_loss)\n    avg_val_loss.append(val_loss)","metadata":{"execution":{"iopub.status.busy":"2023-03-08T12:46:12.886842Z","iopub.execute_input":"2023-03-08T12:46:12.887494Z","iopub.status.idle":"2023-03-08T12:53:07.047409Z","shell.execute_reply.started":"2023-03-08T12:46:12.887458Z","shell.execute_reply":"2023-03-08T12:53:07.046322Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dde2a744e6e8413bb0616a7539a9d620"}},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(range(len(avg_train_loss)),avg_train_loss,'-r');\nplt.plot(range(len(avg_val_loss)),avg_val_loss,'-b');\nplt.legend(['avg_train_loss','avg_val_loss']);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_preds(model,image_path):\n    from PIL import ImageDraw\n    import torchvision.transforms.functional as tf\n    \n    im=Image.open(image_path)\n    draw=ImageDraw.Draw(im)\n    tensor=tf.to_tensor(im)\n    out=model(tensor.to(device=Config.device))\n    out = np.round(out.detach().to('cpu').numpy()).astype(int) #changing real number predictions into nearest integers\n\n\n    for feature in out[0]:\n        x,y=feature[0],feature[1]\n        draw.ellipse((x-2,y-2,x+2,y+2),fill=(255,255,255))\n    return im","metadata":{"execution":{"iopub.status.busy":"2023-03-08T12:53:07.289348Z","iopub.execute_input":"2023-03-08T12:53:07.290059Z","iopub.status.idle":"2023-03-08T12:53:07.297254Z","shell.execute_reply.started":"2023-03-08T12:53:07.290020Z","shell.execute_reply":"2023-03-08T12:53:07.296216Z"},"trusted":true},"execution_count":7,"outputs":[]}]}